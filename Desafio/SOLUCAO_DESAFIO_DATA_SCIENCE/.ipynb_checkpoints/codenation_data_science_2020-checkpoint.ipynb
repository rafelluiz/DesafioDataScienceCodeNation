{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qKZlyoYopM0L"
   },
   "source": [
    "#CodeNation - Descubra as melhores notas de matemática do ENEM 2016"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BfmIOm9mo28U"
   },
   "source": [
    "Olá cientista, tudo bem com você? Esse desafio foi proposto pela **CodeNation** e para você ser aceito aos treinamentos, devia obter ao menos **90% de acerto**.\n",
    "\n",
    "Aqui vou mostrar um guia de como alcancei facilmente **93%** passo a passo.\n",
    "\n",
    "Caso queira as informações sobre o desafio e os arquivos, basta dar uma olhada no meu repositório do git [CodeNation-Data-Science-2020](https://github.com/lpcaldeira/codenation-data-science)\n",
    "\n",
    "- Este tutorial foi feito utilizando o Google Colab\n",
    "- Baixe os arquivos no repositório citado acima e faça upload do **train.csv** e **test.csv** no menu lateral a esquerda em Files > Upload"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0g97rg-ZgbOQ"
   },
   "source": [
    "Não esqueça de acionar a GPU em Runtime > change runtime type > Hardware accelerator > GPU > Save"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-cRVSfyS9bQ7"
   },
   "source": [
    "#Visão geral sobre os dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TJGc3D9OP20T"
   },
   "source": [
    "Importando as libs que serão utilizadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2GSqicxdeu36"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DLJ_e6_9QCET"
   },
   "source": [
    "Configurações do pandas pra exibirem todas as linhas e colunas dos itens solicitados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aLVhg6t0v9LG"
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0pPs3zoHP6Ey"
   },
   "source": [
    "Importando os arquivos de treino e teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0Spp88bbPziT"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'train.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-5bee51faeab9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\",\"\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"UTF8\"\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\",\"\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"UTF8\"\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/PROGRAMACAO/PYTHON/scripts_python/CodeNation/DataScience_06-2020/SOLUCAO_DESAFIO_DATA_SCIENCE/venv/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    674\u001b[0m         )\n\u001b[1;32m    675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/PROGRAMACAO/PYTHON/scripts_python/CodeNation/DataScience_06-2020/SOLUCAO_DESAFIO_DATA_SCIENCE/venv/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 448\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/PROGRAMACAO/PYTHON/scripts_python/CodeNation/DataScience_06-2020/SOLUCAO_DESAFIO_DATA_SCIENCE/venv/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    878\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/PROGRAMACAO/PYTHON/scripts_python/CodeNation/DataScience_06-2020/SOLUCAO_DESAFIO_DATA_SCIENCE/venv/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1112\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1113\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1114\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1115\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1116\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/PROGRAMACAO/PYTHON/scripts_python/CodeNation/DataScience_06-2020/SOLUCAO_DESAFIO_DATA_SCIENCE/venv/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1872\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"compression\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1873\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1874\u001b[0;31m                 \u001b[0msrc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1875\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1876\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'train.csv'"
     ]
    }
   ],
   "source": [
    "df_train = pd.read_csv('train.csv', sep=\",\" , encoding=\"UTF8\" )\n",
    "df_test = pd.read_csv('test.csv', sep=\",\" , encoding=\"UTF8\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lUm7MVytP-cn"
   },
   "source": [
    "Visualizando as colunas que estão no arquivo de testes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "colab_type": "code",
    "id": "arU5MKiaeviv",
    "outputId": "3714fb84-532f-4f3a-f6bb-2747923045f5"
   },
   "outputs": [],
   "source": [
    "df_test.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iEPlm8FGQKd4"
   },
   "source": [
    "Identificando quais campos tem mais correlação com o nosso target/NU_NOTA_MT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "v7kd8WX-evox",
    "outputId": "8192cdb9-ec0d-4908-850e-7ed14e42ba21"
   },
   "outputs": [],
   "source": [
    "# Quanto mais próximo a 1, maior a correlação\n",
    "df_train.corr()['NU_NOTA_MT'].dropna().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_ZB4Ju23QU1n"
   },
   "source": [
    "Criando as colunas que serão utilizadas no modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jERIioXR6bTK"
   },
   "outputs": [],
   "source": [
    "colunas = [\n",
    "    'CO_UF_RESIDENCIA',\n",
    "    'SG_UF_RESIDENCIA',\n",
    "    'NU_IDADE',\n",
    "    'TP_SEXO',\n",
    "    'TP_COR_RACA',\n",
    "    'TP_NACIONALIDADE',\n",
    "    'TP_ST_CONCLUSAO',\n",
    "    'TP_ANO_CONCLUIU',\n",
    "    'TP_ESCOLA',\n",
    "    'TP_ENSINO',\n",
    "    'IN_TREINEIRO',\n",
    "    'TP_DEPENDENCIA_ADM_ESC',\n",
    "    'IN_BAIXA_VISAO',\n",
    "    'IN_CEGUEIRA',\n",
    "    'IN_SURDEZ',\n",
    "    'IN_DISLEXIA',\n",
    "    'IN_DISCALCULIA',\n",
    "    'IN_SABATISTA',\n",
    "    'IN_GESTANTE',\n",
    "    'IN_IDOSO',\n",
    "    'TP_PRESENCA_CN',\n",
    "    'TP_PRESENCA_CH',\n",
    "    'TP_PRESENCA_LC',\n",
    "    'CO_PROVA_CN',\n",
    "    'CO_PROVA_CH',\n",
    "    'CO_PROVA_LC',\n",
    "    'CO_PROVA_MT',\n",
    "    'NU_NOTA_CN',\n",
    "    'NU_NOTA_CH',\n",
    "    'NU_NOTA_LC',\n",
    "    'TP_LINGUA',\n",
    "    'TP_STATUS_REDACAO',\n",
    "    'NU_NOTA_COMP1',\n",
    "    'NU_NOTA_COMP2',\n",
    "    'NU_NOTA_COMP3',\n",
    "    'NU_NOTA_COMP4',\n",
    "    'NU_NOTA_COMP5',\n",
    "    'NU_NOTA_REDACAO',\n",
    "    'Q001',\n",
    "    'Q002',\n",
    "    'Q006',\n",
    "    'Q024',\n",
    "    'Q025',\n",
    "    'Q026',\n",
    "    'Q027',\n",
    "    'Q047'\n",
    "]\n",
    "colunas_corr = [\n",
    "    'NU_NOTA_MT',\n",
    "    'CO_UF_RESIDENCIA',\n",
    "    'SG_UF_RESIDENCIA',\n",
    "    'NU_IDADE',\n",
    "    'TP_SEXO',\n",
    "    'TP_COR_RACA',\n",
    "    'TP_NACIONALIDADE',\n",
    "    'TP_ST_CONCLUSAO',\n",
    "    'TP_ANO_CONCLUIU',\n",
    "    'TP_ESCOLA',\n",
    "    'TP_ENSINO',\n",
    "    'IN_TREINEIRO',\n",
    "    'TP_DEPENDENCIA_ADM_ESC',\n",
    "    'IN_BAIXA_VISAO',\n",
    "    'IN_CEGUEIRA',\n",
    "    'IN_SURDEZ',\n",
    "    'IN_DISLEXIA',\n",
    "    'IN_DISCALCULIA',\n",
    "    'IN_SABATISTA',\n",
    "    'IN_GESTANTE',\n",
    "    'IN_IDOSO',\n",
    "    'TP_PRESENCA_CN',\n",
    "    'TP_PRESENCA_CH',\n",
    "    'TP_PRESENCA_LC',\n",
    "    'CO_PROVA_CN',\n",
    "    'CO_PROVA_CH',\n",
    "    'CO_PROVA_LC',\n",
    "    'CO_PROVA_MT',\n",
    "    'NU_NOTA_CN',\n",
    "    'NU_NOTA_CH',\n",
    "    'NU_NOTA_LC',\n",
    "    'TP_LINGUA',\n",
    "    'TP_STATUS_REDACAO',\n",
    "    'NU_NOTA_COMP1',\n",
    "    'NU_NOTA_COMP2',\n",
    "    'NU_NOTA_COMP3',\n",
    "    'NU_NOTA_COMP4',\n",
    "    'NU_NOTA_COMP5',\n",
    "    'NU_NOTA_REDACAO',\n",
    "    'Q001',\n",
    "    'Q002',\n",
    "    'Q006',\n",
    "    'Q024',\n",
    "    'Q025',\n",
    "    'Q026',\n",
    "    'Q027',\n",
    "    'Q047'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CwNPevKYQPDJ"
   },
   "source": [
    "#Gráficos e correções de valores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "e12g52LOwwre",
    "outputId": "0d685889-cdca-4743-ba58-74d9a231d8d7"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.style.use('ggplot')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oHcMMVYnWc5g"
   },
   "source": [
    "Vamos usar estes campos para visualizar os gráficos, pois possuem maior correlação com o target:\n",
    "\n",
    "> NU_NOTA_LC\n",
    "\n",
    "> NU_NOTA_CN\n",
    "\n",
    "> NU_NOTA_CH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6kaTI1hwQnqx"
   },
   "source": [
    "Quantidade de campos NULOS de cada campo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 816
    },
    "colab_type": "code",
    "id": "jVACpIbLewB8",
    "outputId": "63674aaf-397e-484a-cd44-25ac0a7aa655"
   },
   "outputs": [],
   "source": [
    "df_train[colunas].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BHM3Fp31Sym1"
   },
   "source": [
    "Visualizando campos nulos/NaN nos datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "colab_type": "code",
    "id": "6qgk07gRfzJx",
    "outputId": "9ccee25f-ac51-41a2-883a-707920ec727e"
   },
   "outputs": [],
   "source": [
    "x0 = df_train['NU_NOTA_LC']\n",
    "x1 = df_test['NU_NOTA_LC']\n",
    "sns.distplot(x0)\n",
    "sns.distplot(x1)\n",
    "plt.legend(labels=['Treino','Teste'], ncol=2, loc='upper left');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XlVrRhOzTQrE"
   },
   "source": [
    "Pelo visto, temos muitos campo nulos/NaN, então a minha opção foi substituí-los por zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Fj_NNKRzfzQR",
    "outputId": "d5e3f352-ceb4-4453-f767-ac3081c0f94e"
   },
   "outputs": [],
   "source": [
    "#Caso queira utilizar média, basta descomentar a linha abaixo\n",
    "#df_train = df_train.fillna(df_train.median())\n",
    "#E comentar essa\n",
    "df_train = df_train.fillna(0)\n",
    "\n",
    "# Quantidade de linhas no dataset de treino\n",
    "len(df_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "u2z8_DxJUGRW"
   },
   "source": [
    " Verifica o gráfico de novo (repare agora a quantidade de valores Zero que temos no dataset de TREINO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "colab_type": "code",
    "id": "88IS2ljhfzV7",
    "outputId": "18ba10c8-ec2f-429d-8f22-98eb17ea85d3"
   },
   "outputs": [],
   "source": [
    "x0 = df_train['NU_NOTA_LC']\n",
    "x1 = df_test['NU_NOTA_LC']\n",
    "sns.distplot(x0)\n",
    "sns.distplot(x1)\n",
    "plt.legend(labels=['Treino','Teste'], ncol=2, loc='upper left');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 285
    },
    "colab_type": "code",
    "id": "vEVqqLJQg0Ao",
    "outputId": "ea409d6f-8ab2-46af-a796-2cf7544bc426"
   },
   "outputs": [],
   "source": [
    "# Verifica outro gráfico\n",
    "x0 = df_train['NU_NOTA_CN']\n",
    "x1 = df_test['NU_NOTA_CN']\n",
    "sns.distplot(x0)\n",
    "sns.distplot(x1)\n",
    "plt.legend(labels=['Treino','Teste'], ncol=2, loc='upper left');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "colab_type": "code",
    "id": "jRbUf8zKev_t",
    "outputId": "05539e69-b9ad-440b-829c-11b54411075e"
   },
   "outputs": [],
   "source": [
    "# Verifica outro gráfico\n",
    "x0 = df_train['NU_NOTA_CH']\n",
    "x1 = df_test['NU_NOTA_CH']\n",
    "sns.distplot(x0)\n",
    "sns.distplot(x1)\n",
    "plt.legend(labels=['Treino','Teste'], ncol=2, loc='upper left');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uydv-j7UXdHr"
   },
   "source": [
    "Verificando a quantidade de nulos/NaN no dataset de Teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 833
    },
    "colab_type": "code",
    "id": "QcnhJoXaev9B",
    "outputId": "9e660331-3dfe-4833-da9a-cdddb0a0fc54"
   },
   "outputs": [],
   "source": [
    "# Verificando a quantidade de notas ‘nulls’ na base de test:\n",
    "df_test.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yqkHFnybXL5H"
   },
   "source": [
    "Agora, repetimos a mesma substituição aplicada no dataset de Treino ao dataset de Teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "W-zz_JQVhEiH",
    "outputId": "70acceee-f38e-4ba5-a572-65a3b9cf132a"
   },
   "outputs": [],
   "source": [
    "#Caso queira utilizar média, basta descomentar a linha abaixo\n",
    "#df_test = df_test.fillna(df_test.median())\n",
    "#E comentar essa\n",
    "df_test = df_test.fillna(0)\n",
    "\n",
    "# Quantidade de linhas no dataset de treino\n",
    "len(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VDyGI-W6X53g"
   },
   "source": [
    "Vamos verificar novamente como ficaram os gráficos, percebendo que a coluna Azul (que representa o dataset de testes), também cresceu em valores 0 e diminuiu em nulos/NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "colab_type": "code",
    "id": "rJ9nyAithpMx",
    "outputId": "d6e42dce-a60a-406c-deb1-52bcb243843e"
   },
   "outputs": [],
   "source": [
    "# Verifica outro gráfico\n",
    "x0 = df_train['NU_NOTA_LC']\n",
    "x1 = df_test['NU_NOTA_LC']\n",
    "sns.distplot(x0)\n",
    "sns.distplot(x1)\n",
    "plt.legend(labels=['Treino','Teste'], ncol=2, loc='upper left');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "colab_type": "code",
    "id": "wSK5P8mlev4t",
    "outputId": "fc5f84a6-14f3-41c7-e531-4689a04d3fa5"
   },
   "outputs": [],
   "source": [
    "# Verifica o gráfico de novo\n",
    "x0 = df_train['NU_NOTA_CN']\n",
    "x1 = df_test['NU_NOTA_CN']\n",
    "sns.distplot(x0)\n",
    "sns.distplot(x1)\n",
    "plt.legend(labels=['Treino','Teste'], ncol=2, loc='upper left');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "colab_type": "code",
    "id": "gmHcsDvHhpBj",
    "outputId": "9735cf9d-f883-4cf9-c9f1-bf320b49a1f7"
   },
   "outputs": [],
   "source": [
    "# Verifica outro gráfico\n",
    "x0 = df_train['NU_NOTA_CH']\n",
    "x1 = df_test['NU_NOTA_CH']\n",
    "sns.distplot(x0)\n",
    "sns.distplot(x1)\n",
    "plt.legend(labels=['Treino','Teste'], ncol=2, loc='upper left');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "A3d7RZQGhxEz"
   },
   "source": [
    "#Separando e tratando os dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZvSAL5feYZ6P"
   },
   "source": [
    "Precisamos normalizar os dados tratando/transformando campos do tipo **OBJECT** em **FLOAT**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "n-j1dY0mYo6o"
   },
   "source": [
    "Primeiro, os encontramos nos 2 datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "q9QOuD6g06HJ"
   },
   "outputs": [],
   "source": [
    "train_colunas_do_tipo_objeto = df_train.select_dtypes(include=[object]).columns\n",
    "test_colunas_do_tipo_objeto = df_test.select_dtypes(include=[object]).columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mzKpy76KZgWX"
   },
   "source": [
    "Agora, separamos os valores de cada dataset e os campos que vamos utilizar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "85M9RWjeZghD"
   },
   "outputs": [],
   "source": [
    "# y_train fica com os valores das notas de matemática do Treino\n",
    "y_train = df_train['NU_NOTA_MT']\n",
    "# x_train pega todos os valores que o dataset de Teste possui\n",
    "x_train = df_train[colunas]\n",
    "# x_test tem todos os campos, menos a Inscrição(NU_INSCRICAO)\n",
    "x_test = df_test[colunas]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9huDE6JVYsGI"
   },
   "source": [
    "Depois, podemos usar, por exemplo, o LabelEncoder para tratar cada campo do tipo objeto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "id": "k5oH1kHM0u-Z",
    "outputId": "5d946634-be2c-4557-ec56-1b7e324fbfa4"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "y_train_encoder = LabelEncoder().fit_transform(y_train)\n",
    "\n",
    "for coluna in train_colunas_do_tipo_objeto:\n",
    "  if coluna in colunas and coluna != 'NU_INSCRICAO':\n",
    "    x_train[coluna] = LabelEncoder().fit_transform(x_train[coluna].astype(str))\n",
    "\n",
    "for coluna in test_colunas_do_tipo_objeto:\n",
    "  if coluna in colunas and coluna != 'NU_INSCRICAO':\n",
    "    x_test[coluna] = LabelEncoder().fit_transform(x_test[coluna].astype(str))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HaNbp7TbZ0-V"
   },
   "source": [
    "Importamos os scalers e aplicamos nos dados para aumentar a velocidade de processamento.\n",
    "\n",
    "Neste exemplo, apenas apliquei o Standard mas deixei o Robust junto, para caso você queira fazer alguns testes extras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kHCp6K8ZLzlK"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler, StandardScaler\n",
    "sc = StandardScaler()\n",
    "rb = StandardScaler()\n",
    "x_train_scaler = sc.fit_transform(x_train)  \n",
    "x_test_scaler = sc.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CV7iTRn1aP5p"
   },
   "source": [
    "#Criando os modelos de regressões"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mbNjI-hJaXCB"
   },
   "source": [
    "Estou utilizando aqui o conceito de Pipeline com RandomizedSearchCV (você pode aplicar o GridSearchCV se quiser) para realizar vários testes de regressão e identificar os melhores parâmetros para o meu modelo alcançar ou chegar o mais próximo de 100%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VeZzDBY1a4G9"
   },
   "source": [
    "##O primeiro a ser testado será o AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 748
    },
    "colab_type": "code",
    "id": "pDt67wtrlO9a",
    "outputId": "e11bddfe-b85f-453e-80a7-cc162e8fedda"
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# Instanciamos o Regressor\n",
    "ada = AdaBoostRegressor()\n",
    "# Setamos o Scaler que criamos anteriormente e o Regressor\n",
    "clf = Pipeline([('scaler', sc), ('ada', ada)])\n",
    "\n",
    "# Informamos os parâmetros e variações do Regressor que queremos que o RandomizedSearchCV aplique para nós\n",
    "random_grid = {\n",
    "    'ada__base_estimator': [DecisionTreeRegressor(max_depth=8), DecisionTreeRegressor(max_depth=3)],\n",
    "    'ada__random_state': [0, 42],\n",
    "    'ada__loss': ['linear','square','exponential'],\n",
    "    'ada__n_estimators': [10, 20, 50, 100, 200]\n",
    "}\n",
    "\n",
    "# Informamos mais alguns parâmetros, agora referentes apenas ao RandomizeSearchCV\n",
    "search = RandomizedSearchCV(estimator = clf, param_distributions = random_grid, \n",
    "                            n_iter = 20, cv = 5, verbose = 10, n_jobs = -1)\n",
    "\n",
    "# Aqui efetivamente roda o processo usando o dataset de Treino para treinar o modelo\n",
    "results = search.fit(x_train, y_train)\n",
    "\n",
    "# Aqui mostrará os melhores parâmetros juntamente com o percentual de acerto.\n",
    "# No teste que fiz, o percentual ficou em 99.99963%\n",
    "results.best_score_, results.best_params_, results.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "c8iZk3YesvvH"
   },
   "source": [
    "0.9235217474934994 %\n",
    "\n",
    "Regressor com parâmetros:\n",
    "\n",
    "AdaBoostRegressor(base_estimator=DecisionTreeRegressor(ccp_alpha=0.0,\n",
    "                                                                         criterion='mse',\n",
    "                                                                         max_depth=8,\n",
    "                                                                         max_features=None,\n",
    "                                                                         max_leaf_nodes=None,\n",
    "                                                                         min_impurity_decrease=0.0,\n",
    "                                                                         min_impurity_split=None,\n",
    "                                                                         min_samples_leaf=1,\n",
    "                                                                         min_samples_split=2,\n",
    "                                                                         min_weight_fraction_leaf=0.0,\n",
    "                                                                         presort='deprecated',\n",
    "                                                                         random_state=None,\n",
    "                                                                         splitter='best'),\n",
    "                                    learning_rate=1.0, loss='exponential',\n",
    "                                    n_estimators=10, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aBhqcmnGb3vj"
   },
   "source": [
    "Então, agora que tenho os parâmetros que já me deram 92% de acerto, vou utilizá-los no dataset de Teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WT7yFCI0ra_p"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "ada = AdaBoostRegressor(base_estimator=DecisionTreeRegressor(ccp_alpha=0.0,\n",
    "                                                                         criterion='mse',\n",
    "                                                                         max_depth=8,\n",
    "                                                                         max_features=None,\n",
    "                                                                         max_leaf_nodes=None,\n",
    "                                                                         min_impurity_decrease=0.0,\n",
    "                                                                         min_impurity_split=None,\n",
    "                                                                         min_samples_leaf=1,\n",
    "                                                                         min_samples_split=2,\n",
    "                                                                         min_weight_fraction_leaf=0.0,\n",
    "                                                                         presort='deprecated',\n",
    "                                                                         random_state=None,\n",
    "                                                                         splitter='best'),\n",
    "                                    learning_rate=1.0, loss='exponential',\n",
    "                                    n_estimators=10, random_state=0)\n",
    "\n",
    "# Treinando o nosso modelo com o scaler e encoder que fizemos lá em cima\n",
    "ada.fit(x_train_scaler, y_train_encoder)\n",
    "# Realizando a predição das notas com o dataset de Teste\n",
    "y_pred_test = ada.predict(x_test_scaler)\n",
    "# Exportando o arquivo com as notas geradas\n",
    "answer = pd.DataFrame()\n",
    "answer['NU_INSCRICAO'] = df_test.NU_INSCRICAO\n",
    "answer['NU_NOTA_MT'] = y_pred_test\n",
    "answer.to_csv('answer_ada.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "RF1DzVRahAMs",
    "outputId": "79d2cdf8-7764-41c1-ae6f-487467cd0046"
   },
   "outputs": [],
   "source": [
    "# Teste auxiliar para identificar a acurrácia do modelo usando cross_validation.\n",
    "# Quanto mais perto de 1.0, melhor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(ada, x_test_scaler, y_pred_test, cv=5)\n",
    "print(scores)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SZGbfTJyhHgJ"
   },
   "source": [
    "##O segundo a ser testado será o DecisionTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 901
    },
    "colab_type": "code",
    "id": "AYJxPUSClO6l",
    "outputId": "4eee4266-cfe0-4802-9a4c-a4b3b28f891e"
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "dt = DecisionTreeRegressor()\n",
    "clf = Pipeline([('scaler', sc), ('dt', dt)])\n",
    "\n",
    "random_grid = {\n",
    "    'dt__criterion': ['mse', 'friedman_mse', 'mae'],\n",
    "    'dt__splitter': ['best', 'random'],\n",
    "    'dt__max_depth': [None, 5, 8, 20],\n",
    "    'dt__min_samples_split': [0, 2, 5],\n",
    "    'dt__min_samples_leaf': [0, 1, 5],\n",
    "    'dt__min_weight_fraction_leaf': [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "    'dt__max_features': [0, None, 5, 10, 'auto', 'sqrt', 'log2'],\n",
    "    'dt__random_state': [0, None, 5, 42]\n",
    "}\n",
    "\n",
    "search = RandomizedSearchCV(estimator = clf, param_distributions = random_grid, \n",
    "                            n_iter = 200, cv = 5, verbose = 10, n_jobs = -1)\n",
    "\n",
    "results = search.fit(x_train, y_train)\n",
    "\n",
    "results.best_score_, results.best_params_, results.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TKP_npZruSGB"
   },
   "source": [
    "0.9163452188462285 %\n",
    "\n",
    "Regressor com os parâmetros:\n",
    "\n",
    "DecisionTreeRegressor(ccp_alpha=0.0, criterion='mse',\n",
    "                                        max_depth=8, max_features='auto',\n",
    "                                        max_leaf_nodes=None,\n",
    "                                        min_impurity_decrease=0.0,\n",
    "                                        min_impurity_split=None,\n",
    "                                        min_samples_leaf=1, min_samples_split=2,\n",
    "                                        min_weight_fraction_leaf=0.0,\n",
    "                                        presort='deprecated', random_state=None,\n",
    "                                        splitter='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_oU6M0PqB6K9"
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "dt = DecisionTreeRegressor(ccp_alpha=0.0, criterion='mse',\n",
    "                                        max_depth=8, max_features='auto',\n",
    "                                        max_leaf_nodes=None,\n",
    "                                        min_impurity_decrease=0.0,\n",
    "                                        min_impurity_split=None,\n",
    "                                        min_samples_leaf=1, min_samples_split=2,\n",
    "                                        min_weight_fraction_leaf=0.0,\n",
    "                                        presort='deprecated', random_state=None,\n",
    "                                        splitter='best')\n",
    "# Treinando o nosso modelo através do fit:\n",
    "dt.fit(x_train_scaler, y_train_encoder)\n",
    "# Realizando a predição das notas da nossa base test:\n",
    "y_pred_test = dt.predict(x_test_scaler)\n",
    "answer = pd.DataFrame()\n",
    "answer['NU_INSCRICAO'] = df_test.NU_INSCRICAO\n",
    "answer['NU_NOTA_MT'] = y_pred_test\n",
    "answer.to_csv('answer_dt.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "klLRWi2Pg8yY",
    "outputId": "d0b78620-808f-4ad1-cf53-c4077446d1f8"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(dt, x_test_scaler, y_pred_test, cv=5)\n",
    "print(scores)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sez8NdITiJm7"
   },
   "source": [
    "##O terceiro a ser testado é o RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "Yf_2BcPUlOwC",
    "outputId": "81b547d4-b3ea-4b4f-944a-a27f86bfbafa"
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "rf = RandomForestRegressor()\n",
    "clf = Pipeline([('scaler', sc), ('rf', rf)])\n",
    "\n",
    "random_grid = {\n",
    "    'rf__criterion': ['mse', 'friedman_mse', 'mae'],\n",
    "    'rf__n_estimators': [10, 100, 200, 300],\n",
    "    'rf__max_depth': [None, 5, 8, 20],\n",
    "    'rf__min_samples_split': [0, 2, 5],\n",
    "    'rf__min_samples_leaf': [0, 1, 5, 10],\n",
    "    'rf__max_features': [0, 'auto', 'sqrt', 'log2'],\n",
    "    'rf__n_jobs': [-1],\n",
    "    'rf__verbose': [10],\n",
    "    'rf__random_state': [0, None, 5, 42]\n",
    "}\n",
    "\n",
    "search = RandomizedSearchCV(estimator = clf, param_distributions = random_grid, \n",
    "                            n_iter = 20, cv = 5, verbose = 10, n_jobs = -1)\n",
    "\n",
    "results = search.fit(x_train, y_train)\n",
    "\n",
    "results.best_score_, results.best_params_, results.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-o9AaGStAtuy"
   },
   "source": [
    "0.9254360637203654 %\n",
    "\n",
    "Regressor com os parâmetros:\n",
    "\n",
    "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0,\n",
    "                                        criterion='friedman_mse', max_depth=20,\n",
    "                                        max_features='auto', max_leaf_nodes=None,\n",
    "                                        max_samples=None,\n",
    "                                        min_impurity_decrease=0.0,\n",
    "                                        min_impurity_split=None,\n",
    "                                        min_samples_leaf=5, min_samples_split=5,\n",
    "                                        min_weight_fraction_leaf=0.0,\n",
    "                                        n_estimators=200, n_jobs=-1,\n",
    "                                        oob_score=False, random_state=5,\n",
    "                                        verbose=10, warm_start=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "QXnxhslZCVlS",
    "outputId": "f46ec84e-629d-4a1c-b89d-4fbe33957f64"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rf = RandomForestRegressor(bootstrap=True, ccp_alpha=0.0,\n",
    "                                        criterion='friedman_mse', max_depth=20,\n",
    "                                        max_features='auto', max_leaf_nodes=None,\n",
    "                                        max_samples=None,\n",
    "                                        min_impurity_decrease=0.0,\n",
    "                                        min_impurity_split=None,\n",
    "                                        min_samples_leaf=5, min_samples_split=5,\n",
    "                                        min_weight_fraction_leaf=0.0,\n",
    "                                        n_estimators=200, n_jobs=-1,\n",
    "                                        oob_score=False, random_state=5,\n",
    "                                        verbose=10, warm_start=False)\n",
    "# Treinando o nosso modelo através do fit:\n",
    "rf.fit(x_train_scaler, y_train_encoder)\n",
    "# Realizando a predição das notas da nossa base test:\n",
    "y_pred_test = rf.predict(x_test_scaler)\n",
    "answer = pd.DataFrame()\n",
    "answer['NU_INSCRICAO'] = df_test.NU_INSCRICAO\n",
    "answer['NU_NOTA_MT'] = y_pred_test\n",
    "answer.to_csv('answer_rf.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "BJkw8v2RgyXn",
    "outputId": "5845c0ba-ae8a-4c95-8785-1d90ca5c1cf2"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(rf, x_test_scaler, y_pred_test, cv=5)\n",
    "print(scores)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "es-Zse_p8nea"
   },
   "source": [
    "#Caso você queira aplicar mais alguns algoritmos, segue aqui algumas recomendações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "colab_type": "code",
    "id": "3H2W5258382K",
    "outputId": "bced0589-0fbd-4bc9-a505-2e7a9104ef64"
   },
   "outputs": [],
   "source": [
    "# Outra opção de Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# Outras opções de Regressores\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "\n",
    "# Outra opção de scaler\n",
    "# Primeiro instala\n",
    "!pip install category_encoders\n",
    "# Depois o utiliza da mesma forma que usa o StandardScaler\n",
    "import category_encoders as ce\n",
    "onehotencoder = ce.OneHotEncoder()\n",
    "x_train_onehotencoder = onehotencoder.fit_transform(x_train)\n",
    "x_test_onehotencoder = onehotencoder.fit_transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rzN9wn0worVL"
   },
   "source": [
    "#Script que não permite que o Google Colab desconecte. Assim, você não perde suas execuções que demoram mais de 30 minutos.\n",
    "\n",
    "Basta abrir as opções de desenvolvedor (F12 ou ctrl + shift + i), colar o código abaixo na aba Console e dar Enter.\n",
    "\n",
    "> function ConnectButton(){\n",
    "    const arraydocolab = document.querySelectorAll('.notebook-content .cell.code .cell-gutter paper-icon-button')\n",
    "    arraydocolab[arraydocolab.length - 1].click()\n",
    "    console.log('==== Reconecta a cada 20 minutos ====')\n",
    "}\n",
    "var intervaldocolab = setInterval(ConnectButton,1200000);\n",
    "// se quiser remover isso, basta digitar no console: clearInterval(intervaldocolab)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Jq7K3FFY_2MY"
   },
   "outputs": [],
   "source": [
    "# Mantenha essa célula aqui para garantir o funcionamento do script"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "-cRVSfyS9bQ7",
    "CwNPevKYQPDJ",
    "A3d7RZQGhxEz",
    "CV7iTRn1aP5p",
    "es-Zse_p8nea"
   ],
   "machine_shape": "hm",
   "name": "codenation-data-science-2020.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
